{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINN flow  for MobileNet-V1\n",
    "-------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brevitas Export\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/brevitas_export.PNG\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.util.mobilenet_util as util\n",
    "\n",
    "model = util.export_mobilenet()\n",
    "model.save(\"mobilenet-v1.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of MobileNet-v1 in Netron\n",
    "-----------------------------------------------------\n",
    "* Netron is a visualizer for neural networks and allows interactive investigation of network properties\n",
    "* exported mobilenet consists of 16 layers:\n",
    "    * 1 Convolutional Layer\n",
    "    * 13 Depthwise-Separable Convolutional Layers \n",
    "        * 13 depthwise convolutions\n",
    "        * 13 pointwise convolutions\n",
    "    * 1 Pooling Layer\n",
    "    * 1 Fully-connected Layer\n",
    "    \n",
    "-------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'mobilenet-v1.onnx' at http://0.0.0.0:5918\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://xirxlabs51:5918/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f60b3e947b8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron, showSrc\n",
    "\n",
    "showInNetron(\"mobilenet-v1.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch description of div node\n",
    "------------------------------------------\n",
    "<img src=\"img/div_pytorch.PNG\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Preparation\n",
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/NW_prep.PNG\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "-------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlining\n",
    "------------------------\n",
    "* Main idea behind streamlining: eliminate floating point operations\n",
    "    * moving them around \n",
    "    * collapsing them into one operation\n",
    "    * transforming them into multithresholding nodes\n",
    "  \n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/transformation.PNG\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Streamline(Transformation):\n",
      "    \"\"\"Apply the streamlining transform, see arXiv:1709.04060.\"\"\"\n",
      "\n",
      "    def apply(self, model):\n",
      "        streamline_transformations = [\n",
      "            ConvertSubToAdd(),\n",
      "            ConvertDivToMul(),\n",
      "            BatchNormToAffine(),\n",
      "            ConvertSignToThres(),\n",
      "            AbsorbSignBiasIntoMultiThreshold(),\n",
      "            MoveAddPastMul(),\n",
      "            MoveScalarAddPastMatMul(),\n",
      "            MoveAddPastConv(),\n",
      "            MoveScalarMulPastMatMul(),\n",
      "            MoveScalarMulPastConv(),\n",
      "            MoveAddPastMul(),\n",
      "            CollapseRepeatedAdd(),\n",
      "            CollapseRepeatedMul(),\n",
      "            AbsorbAddIntoMultiThreshold(),\n",
      "            FactorOutMulSignMagnitude(),\n",
      "            AbsorbMulIntoMultiThreshold(),\n",
      "            Absorb1BitMulIntoMatMul(),\n",
      "            Absorb1BitMulIntoConv(),\n",
      "            RoundAndClipThresholds(),\n",
      "        ]\n",
      "        for trn in streamline_transformations:\n",
      "            model = model.transform(trn)\n",
      "            model = model.transform(RemoveIdentityOps())\n",
      "            model = model.transform(GiveUniqueNodeNames())\n",
      "            model = model.transform(GiveReadableTensorNames())\n",
      "            model = model.transform(InferDataTypes())\n",
      "        return (model, False)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from finn.transformation.streamline import Streamline\n",
    "\n",
    "showSrc(Streamline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.core.modelwrapper import ModelWrapper\n",
    "import finn.util.mobilenet_util as util\n",
    "\n",
    "model = ModelWrapper(\"mobilenet-v1.onnx\")\n",
    "# apply streamlining\n",
    "model = model.transform(Streamline())\n",
    "# apply mobilenet specific additional streamlining\n",
    "model = util.additional_streamlining_mobilenet(model)\n",
    "# lowering\n",
    "model = util.lower_mobilenet(model)\n",
    "\n",
    "model.save(\"mobilenet_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:5918\n",
      "Serving 'mobilenet_streamlined.onnx' at http://0.0.0.0:5918\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://xirxlabs51:5918/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f60b3e94f98>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(\"mobilenet_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion to HLS Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/conversion.PNG\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(\"mobilenet_lowered.onnx\")\n",
    "model = util.convert_to_hls_mobilenet(model)\n",
    "model.save(\"mobilenet_hls.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StreamingFCLayer function call\n",
    "------------------------------------------\n",
    "<img src=\"img/streamingfc.PNG\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:5918\n",
      "Serving 'mobilenet_hls.onnx' at http://0.0.0.0:5918\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://xirxlabs51:5918/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f60b3e58fd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(\"mobilenet_hls.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resource Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/folding.PNG\" alt=\"Drawing\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.mobilenet_util import set_mobilenet_folding\n",
    "model = ModelWrapper(\"mobilenet_hls.onnx\")\n",
    "# each tuple is (PE, SIMD, in_fifo_depth, ram_style) for a layer\n",
    "folding = [\n",
    "    (32, 3, 32, \"auto\"),\n",
    "    (16, 16, 32, \"auto\"),\n",
    "    (16, 16, 32, \"auto\"),\n",
    "    (32, 16, 32, \"auto\"),\n",
    "    (16, 16, 32, \"auto\"),\n",
    "    (32, 16, 32, \"auto\"),\n",
    "    (16, 16, 32, \"auto\"),\n",
    "    (32, 16, 32, \"auto\"),\n",
    "    (32, 16, 32, \"auto\"),\n",
    "    (32, 16, 32, \"auto\"),\n",
    "    (32, 16, 32, \"auto\"),\n",
    "    (32, 16, 32, \"auto\"),\n",
    "    (16, 16, 32, \"auto\"),\n",
    "    (32, 16, 32, \"auto\"),\n",
    "    (4, 4, 32, \"auto\"),\n",
    "]\n",
    "model = set_mobilenet_folding(model, folding)\n",
    "model.save(\"mobilenet_folded.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:5918\n",
      "Serving 'mobilenet_folded.onnx' at http://0.0.0.0:5918\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://xirxlabs51:5918/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f60b3e58d68>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(\"mobilenet_folded.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.analysis.fpgadataflow.exp_cycles_per_layer import exp_cycles_per_layer\n",
    "model = ModelWrapper(\"mobilenet_folded.onnx\")\n",
    "exp_cycles_dict = model.analysis(exp_cycles_per_layer)\n",
    "util.show_exp_cycles_plot(model, exp_cycles_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"exp_cycles.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vitis Build\n",
    "----------------------\n",
    "* IPI blocks are created for each layer\n",
    "* Inserting data mover into graph \n",
    "    * to move data from DRAM into the accelerator and to move results back\n",
    "* Stitching IPI blocks together\n",
    "* Vitis build produces xclbin file and a driver\n",
    "\n",
    "<img src=\"img/vitisbuild.PNG\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
